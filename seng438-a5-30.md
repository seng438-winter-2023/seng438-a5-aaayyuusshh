**SENG 438- Software Testing, Reliability, and Quality**

**Lab. Report \#5 – Software Reliability Assessment**

| Group \#:       |   |
|-----------------|---|
| Student Names:  |Aayush Dahal   |
|                 |Justin Kuhn   |
|                 |Sheroze Nasir   |

# Introduction

# 

# Assessment Using Reliability Growth Testing 

# Assessment Using Reliability Demonstration Chart 

## 3 plots for MTTFmin, twice and half of it for your test data

_MTTFmin_

![Screen Shot 2023-04-07 at 9 56 37 PM](https://user-images.githubusercontent.com/80851741/230705228-85df2663-c453-4c35-beb6-4b85bc141c31.png)

_Double_

![Screen Shot 2023-04-07 at 9 57 24 PM](https://user-images.githubusercontent.com/80851741/230705236-ac01cd74-1967-4775-a3e1-d7b14ad68b91.png)

_Half_

![Screen Shot 2023-04-07 at 9 56 58 PM](https://user-images.githubusercontent.com/80851741/230705233-c3cf79dc-47df-428d-991d-67c80bee81f5.png)


## Explain your evaluation and justification of how you decide the MTTFmin
- Before performing RDC testing and deciding the MTTF min, we picked the failure data set (CSR1) : this is equivalent to actually collecting failure data in a real world scenario.
- Discrimination Ratio (acceptable error in estimating failure intensity) is set to 2
- Customer Risk (probability the developer is willing to falsely say that a target failure is met when it is not) is set to 0.1 which is 10%.
- Developer Risk (probability that the developer is willing to falsely say that a target failure is not met when it is) is set to 0.1 which is 10%.
- Next, we decided on the target MTTF min (mean time to failure)
  - The target MTTF min is decided to be 0.1 failure/second 
  - This number was determined through trail and error testing of the failure data file. We picked the number that barely touched the accept region and picked that to be our MTTF min.
- Normalize the failure data based on the target MTTF and use the normalized failure data for RDC testing and analyze the trends.

## A discussion on the advantages and disadvantages of RDC

**Advantages:**
- A cost effective, versatile, and time effective way of analyzing reliability of  a system. 
- Provides relatively accurate failure rate data for a system.
- Effective in testing reliability of smaller systems.
- Takes into account the discrimination ratio, customer risk, and developer risk which leads to more accurate reliability results.

**Disadvantages:**
- Although, it indicates if a SUT is acceptable or not, it doesn’t provide an exact quantitative value to demonstrate the reliability of a SUT.
- RDC (especially the SRTAT tool used in this assignment) only accepts limited data types/file format which makes it restrictive to certain data types only.
- Not as effective in testing reliability of large scale systems.


# Comparison of Results

Reliability Growth Testing (RGT) and Reliability Demonstration Chart (RDC) results both show that the software's failure rate/reliability improved with continued testing. Reliability Growth Testing (RGT) demonstrated a gradual decrease in the cumulative failure rate which is indicative of increased reliability.  Similarly, Reliability Demonstration Chart (RDC) demonstrated an improvement in failure rate as the system moved from "continue" to "accept" regions, implying improved MTTF metrics over time. When analyzing the data, Reliability Demonstration Chart (RDC) also takes into account the discrimination ratio, customer risk, and developer risk. 

The conclusion of both RGT (Reliability Growth Testing) and RDC (Reliability Demo Chart) testing techniques were the same; both techniques classified the SUT (System under Test) to be reliable as testing is continued as time passes. RGT (Reliability Growth Testing) and RDC (Reliability Demo Chart) both indicate improved reliability over time, seen through slower cumulative failure rate increases and movement to the accept region.


# Discussion on Similarity and Differences of the Two Techniques

# How the team work/effort was divided and managed

# 

# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the lab itself
